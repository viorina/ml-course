{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['user_id', 'friend_id']\n",
    "df = pd.read_csv('Gowalla_edges.txt', sep='\\t', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>friend_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  friend_id\n",
       "0        0          1\n",
       "1        0          2\n",
       "2        0          3\n",
       "3        0          4\n",
       "4        0          5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1900654 entries, 0 to 1900653\n",
      "Data columns (total 2 columns):\n",
      "user_id      int64\n",
      "friend_id    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 29.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read check-in information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['user_id', 'time', 'latitude', 'longitude', 'location_id']\n",
    "df_checkins = pd.read_csv('Gowalla_totalCheckins.txt', sep='\\t', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-19T23:55:27Z</td>\n",
       "      <td>30.235909</td>\n",
       "      <td>-97.795140</td>\n",
       "      <td>22847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-18T22:17:43Z</td>\n",
       "      <td>30.269103</td>\n",
       "      <td>-97.749395</td>\n",
       "      <td>420315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-17T23:42:03Z</td>\n",
       "      <td>30.255731</td>\n",
       "      <td>-97.763386</td>\n",
       "      <td>316637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-17T19:26:05Z</td>\n",
       "      <td>30.263418</td>\n",
       "      <td>-97.757597</td>\n",
       "      <td>16516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-16T18:50:42Z</td>\n",
       "      <td>30.274292</td>\n",
       "      <td>-97.740523</td>\n",
       "      <td>5535878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                  time   latitude  longitude  location_id\n",
       "0        0  2010-10-19T23:55:27Z  30.235909 -97.795140        22847\n",
       "1        0  2010-10-18T22:17:43Z  30.269103 -97.749395       420315\n",
       "2        0  2010-10-17T23:42:03Z  30.255731 -97.763386       316637\n",
       "3        0  2010-10-17T19:26:05Z  30.263418 -97.757597        16516\n",
       "4        0  2010-10-16T18:50:42Z  30.274292 -97.740523      5535878"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checkins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6442892 entries, 0 to 6442891\n",
      "Data columns (total 5 columns):\n",
      "user_id        int64\n",
      "time           object\n",
      "latitude       float64\n",
      "longitude      float64\n",
      "location_id    int64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 245.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_checkins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkins.drop(columns=['time', 'latitude', 'longitude'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_checkins['user_id'].nunique() == df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove users from the main dataframe which are not available in check-in data and renumber users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All users need to offer recommendations, but this task assumes that the quality assessment is carried out on the basis of only those users who have check-ins. So, as for me, this action is justified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent = set(range(df['user_id'].nunique())) - set(df_checkins['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['user_id'].isin(absent) & ~df['friend_id'].isin(absent)]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_idx, idx_to_uid = {}, {}\n",
    "for idx, user_id in enumerate(df['user_id'].unique()):\n",
    "    uid_to_idx[user_id] = idx\n",
    "    idx_to_uid[idx] = user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ids(row, mapper):\n",
    "    return mapper[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'user_id'] = df['user_id'].apply(map_ids, args=[uid_to_idx]).values\n",
    "df.loc[:, 'friend_id'] = df['friend_id'].apply(map_ids, args=[uid_to_idx]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize S (Similarity), A (Availability) and R (Responsibility) matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df['user_id'].values\n",
    "cols = df['friend_id'].values\n",
    "data = np.ones(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_mtx = sps.coo_matrix((data, (rows, cols)), shape=(n_users, n_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/scipy/sparse/compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "S = coo_mtx.tocsr()\n",
    "S.setdiag(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, R = S.copy(), S.copy()\n",
    "A.data, R.data = np.zeros(len(S.data), dtype=np.float64), np.zeros(len(S.data), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some auxiliary arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indptr = S.indptr\n",
    "indices = S.indices\n",
    "ind_range = np.arange(n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nz_cols = [indices[start_idx:end_idx].tolist() \n",
    "           for start_idx, end_idx in zip(indptr, indptr[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_col = [dict(zip(ind_range, chunk)) for chunk in nz_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP-algorithm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_generator(X):\n",
    "    for start_idx, end_idx in zip(indptr, indptr[1:]):\n",
    "        yield X.data[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_max(X):\n",
    "    m_ind, m_val = [], []\n",
    "\n",
    "    for row in row_generator(X):\n",
    "        m_ind.append(np.argmax(row))\n",
    "        m_val.append(np.max(row))\n",
    "\n",
    "    # assign the corresponding max value for each element of sparse matrix data\n",
    "    m_arr = np.repeat(np.array(m_val).T, np.diff(indptr))\n",
    "    return m_ind, m_val, m_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_r(A, S, R, damping=0.5):\n",
    "    temp = S.copy()\n",
    "    temp.data += A.data\n",
    "\n",
    "    fm_ind, fm_val, fm_arr = row_max(temp)\n",
    "    temp[ind_range, fm_ind] = -np.inf\n",
    "    _, sm_val, sm_arr = row_max(temp)\n",
    "\n",
    "    # replace first maximum values by second ones where col_idx is the index of max value\n",
    "    for idx, val in enumerate(indptr[:-1]):\n",
    "        col_idx = val + fm_ind[idx]\n",
    "        fm_arr[col_idx] = sm_arr[col_idx]\n",
    "\n",
    "    R_new = S.copy()\n",
    "    R_new.data = R.data * damping + (1 - damping) * (R_new.data - fm_arr)\n",
    "    return R_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_a(R, A, damping=0.5):\n",
    "    A_new = R.copy()\n",
    "    A_new.setdiag(0)\n",
    "    A_new[A_new < 0] = 0\n",
    "\n",
    "    col_sums = np.sum(A_new, axis=0).A.flatten()\n",
    "    arr_sums = R.diagonal() + col_sums\n",
    "    \n",
    "    # also substract values that should not be included into the sums\n",
    "    A_new.data = np.minimum(0, arr_sums[indices] - A_new.data)\n",
    "\n",
    "    A_new.setdiag(col_sums)\n",
    "    A_new.data = A.data * damping + (1 - damping) * A_new.data\n",
    "    return A_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(A, R):\n",
    "    temp = A.copy()\n",
    "    temp.data += R.data\n",
    "    ind_data, _, _ = row_max(temp)\n",
    "\n",
    "    return [mapper[idx] for idx, mapper in zip(ind_data, idx_to_col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 300\n",
    "exemplars_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/scipy/sparse/compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(max_iters):\n",
    "    R = update_r(A, S, R)\n",
    "    A = update_a(R, A)\n",
    "    c = labels(A, R)\n",
    "\n",
    "    exemplars_log.append(c)\n",
    "\n",
    "end_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 26 minutes\n"
     ]
    }
   ],
   "source": [
    "timedelta = end_time - start_time\n",
    "\n",
    "print(f\"Training took {timedelta.seconds // 60} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter(exemplars_log[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of exemplars (clusters): 29227\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of exemplars (clusters): {len(counter)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 602), (1237, 464), (1, 335), (1935, 299), (400, 296)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hide check-ins from the part of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exemplars = pd.DataFrame({\n",
    "    'user_id': np.arange(n_users),\n",
    "    'exemplar_id': exemplars_log[-1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exemplars.loc[:, 'user_id'] = df_exemplars['user_id'].apply(map_ids, args=[idx_to_uid]).values\n",
    "df_exemplars.loc[:, 'exemplar_id'] = df_exemplars['exemplar_id'].apply(map_ids, args=[idx_to_uid]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perc = 90\n",
    "n_train = n_users // 100 * train_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89550"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df_exemplars['user_id'].unique()\n",
    "np.random.shuffle(users)\n",
    "train, test = users[:n_train], users[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count check-ins for every cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = collections.defaultdict(list)\n",
    "\n",
    "for user_id, exemplar_id in df_exemplars.itertuples(index=False): \n",
    "    if not (exemplar_id == user_id and exemplar_id in test):\n",
    "        clusters[exemplar_id].append(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = collections.defaultdict(collections.Counter)\n",
    "\n",
    "for exemplar_id, cluster in clusters.items():\n",
    "    checkins = df_checkins[df_checkins['user_id'].isin(cluster)]['location_id'].values\n",
    "    locations[exemplar_id].update(checkins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get recommendations for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_exemplars[df_exemplars['user_id'].isin(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_checkins = {}\n",
    "recommendations = {}\n",
    "\n",
    "for user_id, exemplar_id in df_test.itertuples(index=False):\n",
    "    checkins = df_checkins[df_checkins['user_id'] == user_id]['location_id'].values\n",
    "    test_checkins[user_id] = checkins\n",
    "\n",
    "    top = [loc_id for loc_id, counts in locations[exemplar_id].most_common(n_top)]\n",
    "    recommendations[user_id] = top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for user_id, checkins in test_checkins.items():\n",
    "    top = recommendations[user_id]\n",
    "    n_misses = n_top - len(top)\n",
    "\n",
    "    acc = np.maximum(0, (len(set(top) & set(checkins)) - n_misses) / n_top)\n",
    "    scores.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18054529112154202"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 5123,\n",
       "         0.2: 911,\n",
       "         0.1: 1533,\n",
       "         0.7: 178,\n",
       "         0.3: 562,\n",
       "         0.5: 273,\n",
       "         0.4: 420,\n",
       "         1.0: 480,\n",
       "         0.6: 235,\n",
       "         0.9: 152,\n",
       "         0.8: 146})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty recommendations lists: 904\n"
     ]
    }
   ],
   "source": [
    "n_empty = sum(not val for val in recommendations.values())\n",
    "\n",
    "print(f\"Number of empty recommendations lists: {n_empty}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
